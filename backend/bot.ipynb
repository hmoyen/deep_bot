{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb2cb16",
   "metadata": {},
   "source": [
    "# **Step 1: Install Dependencies**\n",
    "Before running the code, ensure you have the necessary packages installed.\n",
    "\n",
    "## Install Ollama\n",
    "Ollama is required for embeddings and chat-based interactions.\n",
    "\n",
    "```bash\n",
    "# Install Ollama\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Pull the DeepSeek-R1 model\n",
    "ollama pull deepseek-r1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec53a0a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Load the PDF and Create Embeddings**\n",
    "\n",
    "# **Step 2: Load and Process the PDF**\n",
    "We will:\n",
    "1. Load a PDF using `PyMuPDFLoader`.\n",
    "2. Split it into smaller text chunks for efficient retrieval.\n",
    "3. Generate embeddings using `OllamaEmbeddings` with DeepSeek-R1.\n",
    "4. Store these embeddings in a **ChromaDB** vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163ef813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in ./venv/lib/python3.12/site-packages (5.17.0)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.12/site-packages (0.3.18)\n",
      "Requirement already satisfied: chromadb in ./venv/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.12/site-packages (1.25.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in ./venv/lib/python3.12/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./venv/lib/python3.12/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in ./venv/lib/python3.12/site-packages (from gradio) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in ./venv/lib/python3.12/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.1 in ./venv/lib/python3.12/site-packages (from gradio) (1.7.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in ./venv/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in ./venv/lib/python3.12/site-packages (from gradio) (0.29.1)\n",
      "Requirement already satisfied: jinja2<4.0 in ./venv/lib/python3.12/site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./venv/lib/python3.12/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in ./venv/lib/python3.12/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in ./venv/lib/python3.12/site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in ./venv/lib/python3.12/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in ./venv/lib/python3.12/site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in ./venv/lib/python3.12/site-packages (from gradio) (2.10.6)\n",
      "Requirement already satisfied: pydub in ./venv/lib/python3.12/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in ./venv/lib/python3.12/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in ./venv/lib/python3.12/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in ./venv/lib/python3.12/site-packages (from gradio) (0.9.7)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in ./venv/lib/python3.12/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./venv/lib/python3.12/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in ./venv/lib/python3.12/site-packages (from gradio) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in ./venv/lib/python3.12/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./venv/lib/python3.12/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./venv/lib/python3.12/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from gradio-client==1.7.1->gradio) (2025.2.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in ./venv/lib/python3.12/site-packages (from gradio-client==1.7.1->gradio) (14.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.37)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./venv/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in ./venv/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./venv/lib/python3.12/site-packages (from chromadb) (3.14.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./venv/lib/python3.12/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./venv/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./venv/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./venv/lib/python3.12/site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./venv/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./venv/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./venv/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./venv/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./venv/lib/python3.12/site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./venv/lib/python3.12/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./venv/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./venv/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.12/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in ./venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in ./venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio langchain langchain-community chromadb pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9657b3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lena/deep_bot/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gradio as gr\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901d87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the document\n",
    "loader = PyMuPDFLoader(\"document-20-24.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f990d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282329/3492310573.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"deepseek-r1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deleting collection: Collection foundations_of_llms does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282329/3492310573.py:32: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  retriever = Chroma(collection_name=\"foundations_of_llms\", client=client, embedding_function=embedding_function).as_retriever()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize embeddings model\n",
    "embedding_function = OllamaEmbeddings(model=\"deepseek-r1\")\n",
    "\n",
    "# Generate embeddings in parallel\n",
    "def generate_embedding(chunk):\n",
    "    return embedding_function.embed_query(chunk.page_content)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings = list(executor.map(generate_embedding, chunks))\n",
    "\n",
    "# Initialize Chroma client\n",
    "client = Client(Settings())\n",
    "\n",
    "# Delete and create new collection\n",
    "try:\n",
    "    client.delete_collection(name=\"foundations_of_llms\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error deleting collection: {e}\")\n",
    "\n",
    "collection = client.create_collection(name=\"foundations_of_llms\")\n",
    "\n",
    "# Add documents and embeddings to Chroma\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk.page_content], \n",
    "        metadatas=[{'id': idx}], \n",
    "        embeddings=[embeddings[idx]], \n",
    "        ids=[str(idx)]\n",
    "    )\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = Chroma(collection_name=\"foundations_of_llms\", client=client, embedding_function=embedding_function).as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b85cc",
   "metadata": {},
   "source": [
    "# **Step 3: Context Retrieval and Chat**\n",
    "Now, we will:\n",
    "1. **Retrieve** relevant sections from ChromaDB based on user queries.\n",
    "2. **Generate responses** using `Ollama` with DeepSeek-R1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e080eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for answering questions\n",
    "llm = Ollama(model=\"deepseek-r1\")\n",
    "\n",
    "def retrieve_context(question):\n",
    "    \"\"\"Retrieve relevant context from stored embeddings.\"\"\"\n",
    "    results = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "    return context\n",
    "\n",
    "def query_deepseek(question, context):\n",
    "    \"\"\"Use DeepSeek-R1 to generate an answer.\"\"\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # Clean response\n",
    "    final_answer = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
    "    return final_answer\n",
    "\n",
    "def ask_question(question):\n",
    "    \"\"\"Retrieve context and answer the question.\"\"\"\n",
    "    context = retrieve_context(question)\n",
    "    answer = query_deepseek(question, context)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b498303",
   "metadata": {},
   "source": [
    "# **Step 4: Deploy the Chatbot UI**\n",
    "Finally, we will use **Gradio** to create a simple web interface where users can input their questions and receive answers based on the processed PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42882adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [282329]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:7650 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42726 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:42726 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [282329]\n",
      "Exception ignored in: <coroutine object start_server at 0x73de8e8cb140>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyError: '__import__'\n",
      "Exception ignored in: <coroutine object start_server at 0x73de8e8cb140>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyError: '__import__'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m start_server()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Run Gradio on a different port\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7860\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use `share=True` if you want a public link\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_bot/venv/lib/python3.12/site-packages/gradio/blocks.py:2570\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[1;32m   2565\u001b[0m     (\n\u001b[1;32m   2566\u001b[0m         server_name,\n\u001b[1;32m   2567\u001b[0m         server_port,\n\u001b[1;32m   2568\u001b[0m         local_url,\n\u001b[1;32m   2569\u001b[0m         server,\n\u001b[0;32m-> 2570\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name \u001b[38;5;241m=\u001b[39m server_name\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_url \u001b[38;5;241m=\u001b[39m local_url\n",
      "File \u001b[0;32m~/deep_bot/venv/lib/python3.12/site-packages/gradio/http_server.py:156\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     path_to_local_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import gradio as gr\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class QuestionRequest(BaseModel):\n",
    "    question: str\n",
    "\n",
    "# FastAPI endpoint\n",
    "@app.post(\"/api/predict\")\n",
    "async def predict(request: QuestionRequest):\n",
    "    answer = ask_question(request.question)  # Call your RAG pipeline\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"RAG Chatbot: Foundations of LLMs\",\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()  # Allows running an event loop inside Jupyter\n",
    "\n",
    "async def start_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=7650)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "# Run FastAPI server\n",
    "await start_server()\n",
    "\n",
    "# Run Gradio on a different port\n",
    "interface.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)  # Use `share=True` if you want a public link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e59dc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-33 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/uvicorn/server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/nest_asyncio.py\", line 26, in run\n",
      "    loop = asyncio.get_event_loop()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/nest_asyncio.py\", line 40, in _get_event_loop\n",
      "    loop = events.get_event_loop_policy().get_event_loop()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/nest_asyncio.py\", line 67, in get_event_loop\n",
      "    _patch_loop(loop)\n",
      "  File \"/home/lena/deep_bot/venv/lib/python3.12/site-packages/nest_asyncio.py\", line 193, in _patch_loop\n",
      "    raise ValueError('Can\\'t patch loop of type %s' % type(loop))\n",
      "ValueError: Can't patch loop of type <class 'uvloop.Loop'>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 9990-9990. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m interface \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[1;32m      3\u001b[0m     fn\u001b[38;5;241m=\u001b[39mask_question,\n\u001b[1;32m      4\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsk any question about the Volvo manual book. Powered by DeepSeek-R1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Launch the interface\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9990\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use `share=True` if you want a public link\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_bot/venv/lib/python3.12/site-packages/gradio/blocks.py:2570\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[1;32m   2565\u001b[0m     (\n\u001b[1;32m   2566\u001b[0m         server_name,\n\u001b[1;32m   2567\u001b[0m         server_port,\n\u001b[1;32m   2568\u001b[0m         local_url,\n\u001b[1;32m   2569\u001b[0m         server,\n\u001b[0;32m-> 2570\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name \u001b[38;5;241m=\u001b[39m server_name\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_url \u001b[38;5;241m=\u001b[39m local_url\n",
      "File \u001b[0;32m~/deep_bot/venv/lib/python3.12/site-packages/gradio/http_server.py:156\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     path_to_local_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot find empty port in range: 9990-9990. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "# Set up the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Volvo Chatbot: Troubleshooting\",\n",
    "    description=\"Ask any question about the Volvo manual book. Powered by DeepSeek-R1.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(server_name=\"0.0.0.0\", server_port=9990, share=True)  # Use `share=True` if you want a public link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df6282",
   "metadata": {},
   "source": [
    "# Final Notes\n",
    "\n",
    "    üìÑ This notebook will process the PDF once and store embeddings in ChromaDB, so you don‚Äôt need to reprocess it every time.\n",
    "    ‚ö° The chatbot retrieves only relevant sections before generating an answer using DeepSeek-R1.\n",
    "    üöÄ Gradio provides an easy-to-use UI for interacting with the chatbot.\n",
    "\n",
    "Try running each cell one by one in a Jupyter Notebook, and let me know if you need any modifications! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
